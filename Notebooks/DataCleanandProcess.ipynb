{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project- Data Clean and Process Workbook\n",
    "Cary Mosley, May 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import calendar, time\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import word_tokenize\n",
    "import string, re \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"once\")\n",
    "\n",
    "pd.reset_option('max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean NYT Article Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 2005 1\n",
      "2006 1\n",
      "error 2006 2\n",
      "2007 1\n",
      "2007 2\n",
      "2008 1\n",
      "2008 2\n",
      "2009 1\n",
      "2009 2\n",
      "2010 1\n",
      "2010 2\n",
      "2011 1\n",
      "2011 2\n",
      "2012 1\n",
      "2012 2\n",
      "2013 1\n",
      "2013 2\n",
      "2014 1\n",
      "2014 2\n",
      "2015 1\n",
      "2015 2\n",
      "2016 1\n",
      "2016 2\n",
      "2017 1\n",
      "2017 2\n",
      "2018 1\n",
      "2018 2\n",
      "2019 1\n",
      "2019 2\n",
      "2020 1\n",
      "error 2020 2\n"
     ]
    }
   ],
   "source": [
    "#Set Years\n",
    "years = range(2005,2021)\n",
    "\n",
    "#Select keywords for articles\n",
    "keywords = ['Stock','Market','Finance','Business','Price','Debt','Portfolio','SP500',\n",
    "            'Nasdaq','Dow Jones']\n",
    "\n",
    "#Create DataFrame\n",
    "nyt_df_final = pd.DataFrame(columns=['Date', 'Headline','Snippet'])\n",
    "\n",
    "#Select just the headlines and snippets containing keywords\n",
    "for year in years:\n",
    "    \n",
    "    try:\n",
    "        #read in csv data\n",
    "        path = '../Data/nyt'+str(year)+'1.csv'\n",
    "        nyt_df = pd.read_csv(path,index_col=None)\n",
    "        nyt_df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "        \n",
    "        #select date and convert to datetime object\n",
    "        nyt_df['Date']=nyt_df['Date'].apply(lambda x: x[0:10])\n",
    "        nyt_df['Date']=pd.to_datetime(nyt_df['Date'])\n",
    "        \n",
    "        #all headlines are there but some snippets are missing\n",
    "        nyt_df.dropna(inplace=True)\n",
    "        \n",
    "        #select headlines and snippets containing the keywords\n",
    "        nyt_df_headlines = nyt_df[nyt_df['Headline'].str.contains('|'.join(keywords))]\n",
    "        nyt_df_headlines = nyt_df_headlines[~nyt_df_headlines[\"Headline\"].str.contains('Corrections')]\n",
    "        nyt_df_snippets = nyt_df[nyt_df['Snippet'].str.contains('|'.join(keywords))]\n",
    "        \n",
    "        #concatenate dataframes\n",
    "        nyt_df_final = pd.concat([nyt_df_final,nyt_df_headlines,nyt_df_snippets])\n",
    "        print(year,'1')\n",
    "    except:\n",
    "        print('error',year,'1')\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        #read in csv data\n",
    "        path = '../Data/nyt'+str(year)+'2.csv'\n",
    "        nyt_df = pd.read_csv(path,index_col=None)\n",
    "        nyt_df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "        \n",
    "        #select date and convert to datetime object\n",
    "        nyt_df['Date']=nyt_df['Date'].apply(lambda x: x[0:10])\n",
    "        nyt_df['Date']=pd.to_datetime(nyt_df['Date'])\n",
    "        \n",
    "        #all headlines are there but some snippets are missing\n",
    "        nyt_df.dropna(inplace=True)\n",
    "        \n",
    "        #select headlines and snippets containing the keywords\n",
    "        nyt_df_headlines = nyt_df[nyt_df['Headline'].str.contains('|'.join(keywords))]\n",
    "        nyt_df_headlines = nyt_df_headlines[~nyt_df_headlines[\"Headline\"].str.contains('Corrections')]\n",
    "        nyt_df_snippets = nyt_df[nyt_df['Snippet'].str.contains('|'.join(keywords))]\n",
    "        \n",
    "        #concatenate dataframes\n",
    "        nyt_df_final = pd.concat([nyt_df_final,nyt_df_headlines,nyt_df_snippets])\n",
    "        print(year,'2')\n",
    "    except:\n",
    "        print('error',year,'2')\n",
    "        continue\n",
    "\n",
    "#Set the nyt_df_final index as the Date\n",
    "nyt_df_final.set_index('Date', inplace=True)\n",
    "nyt_df_final.drop_duplicates(inplace=True)\n",
    "#Write to pickle\n",
    "nyt_df_final.to_pickle('../Data/nyt_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34930, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt_df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Snippet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>Glass Makers Fined for Price Fixing</td>\n",
       "      <td>The European Commission issued one of its larg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>2 New Captains of the Economy Face Volatile Gl...</td>\n",
       "      <td>One reached the pinnacle of wealth and prestig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>For Google, M&amp;A is Bad Business</td>\n",
       "      <td>Google on Wednesday poured cold water on specu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>Nasdaq's Greifeld Plays the Tortoise in L.S.E....</td>\n",
       "      <td>Nasdaq's chief executive, Robert Greifeld, is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>Glass Makers Fined for Price Fixing</td>\n",
       "      <td>The European Commission issued one of its larg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Headline  \\\n",
       "Date                                                            \n",
       "2006-06-01                Glass Makers Fined for Price Fixing   \n",
       "2006-06-01  2 New Captains of the Economy Face Volatile Gl...   \n",
       "2006-06-01                    For Google, M&A is Bad Business   \n",
       "2006-06-01  Nasdaq's Greifeld Plays the Tortoise in L.S.E....   \n",
       "2006-06-01                Glass Makers Fined for Price Fixing   \n",
       "\n",
       "                                                      Snippet  \n",
       "Date                                                           \n",
       "2006-06-01  The European Commission issued one of its larg...  \n",
       "2006-06-01  One reached the pinnacle of wealth and prestig...  \n",
       "2006-06-01  Google on Wednesday poured cold water on specu...  \n",
       "2006-06-01  Nasdaq's chief executive, Robert Greifeld, is ...  \n",
       "2006-06-01  The European Commission issued one of its larg...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt_df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Ticker Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Ticker Data\n",
    "spy_df = pd.read_csv('../Data/spy.csv')\n",
    "vix_df = pd.read_csv('../Data/vix.csv')\n",
    "qqq_df = pd.read_csv('../Data/qqq.csv')\n",
    "iwm_df = pd.read_csv('../Data/iwm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Date to datetime\n",
    "spy_df['Date'] = pd.to_datetime(spy_df['Date'])\n",
    "vix_df['Date'] = pd.to_datetime(vix_df['Date'])\n",
    "qqq_df['Date'] = pd.to_datetime(qqq_df['Date'])\n",
    "iwm_df['Date'] = pd.to_datetime(iwm_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the Date as the index\n",
    "spy_df.set_index('Date', inplace=True)\n",
    "vix_df.set_index('Date', inplace=True)\n",
    "qqq_df.set_index('Date', inplace=True)\n",
    "iwm_df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SPY \n",
      " Adj Close    0\n",
      "dtype: int64\n",
      " VIX \n",
      " Adj Close    0\n",
      "dtype: int64\n",
      "QQQ \n",
      " Adj Close    0\n",
      "dtype: int64\n",
      "IWM \n",
      " Adj Close    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check for null values\n",
    "print(' SPY \\n',spy_df.isna().sum())\n",
    "print(' VIX \\n',vix_df.isna().sum())\n",
    "print('QQQ \\n', qqq_df.isna().sum())\n",
    "print('IWM \\n', iwm_df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values which is expected due to the data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will export all of these seperate dataframes to pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spy_df.to_pickle('../Data/spy_df')\n",
    "vix_df.to_pickle('../Data/vix_df')\n",
    "qqq_df.to_pickle('../Data/qqq_df')\n",
    "iwm_df.to_pickle('../Data/iwm_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in 3 sentiment csv files\n",
    "AAII_df = pd.read_csv('../Data/AAII.csv')\n",
    "NAAIM_df = pd.read_csv('../Data/NAAIM.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Date to datetime format\n",
    "AAII_df['Date'] = pd.to_datetime(AAII_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Date to datetime format\n",
    "NAAIM_df['Date'] = pd.to_datetime(NAAIM_df['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that moving the date of the NAAIM data forward by one will result in all the dates being in alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAAIM_df['Date'] = NAAIM_df['Date'] + pd.Timedelta('1 day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to adjust the first NAAIM date back two days to get them in line. After that everything is set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NAAIM_df['Date'].loc[0] = NAAIM_df['Date'].loc[0] - pd.Timedelta('2 days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2006-06-29 00:00:00')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAAIM_df['Date'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the Date as the index\n",
    "AAII_df.set_index('Date', inplace=True)\n",
    "NAAIM_df.set_index('Date', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AAII \n",
      " Bullish             0\n",
      "Neutral             0\n",
      "Bearish             0\n",
      "Bull-Bear Spread    0\n",
      "dtype: int64\n",
      " NAAIM \n",
      " Mean/Average             0\n",
      "Most Bearish Response    0\n",
      "Quart 2 (median)         0\n",
      "Most Bullish Response    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check for null values\n",
    "print(' AAII \\n',AAII_df.isna().sum())\n",
    "print(' NAAIM \\n',NAAIM_df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns\n",
    "AAII_df.rename(columns={\"Bull-Bear Spread\": \"Spread\"},inplace=True)\n",
    "\n",
    "NAAIM_df.rename(columns={\"Mean/Average\": \"Mean\",\"Quart 2 (median)\": \"Median\",\"Most Bearish Response\": \"MaxBear\",\"Most Bullish Response\": \"MaxBull\"},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.concat([AAII_df,NAAIM_df],axis=1,join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bullish</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Bearish</th>\n",
       "      <th>Spread</th>\n",
       "      <th>Mean</th>\n",
       "      <th>MaxBear</th>\n",
       "      <th>Median</th>\n",
       "      <th>MaxBull</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2006-06-29</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.216400</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>-0.011700</td>\n",
       "      <td>56.33</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-06</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>0.196700</td>\n",
       "      <td>0.426200</td>\n",
       "      <td>-0.049200</td>\n",
       "      <td>19.44</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-13</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>0.240900</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>-0.029200</td>\n",
       "      <td>31.20</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-20</td>\n",
       "      <td>0.238500</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>-0.339500</td>\n",
       "      <td>18.76</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-27</td>\n",
       "      <td>0.348800</td>\n",
       "      <td>0.220900</td>\n",
       "      <td>0.430200</td>\n",
       "      <td>-0.081400</td>\n",
       "      <td>17.38</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>0.342391</td>\n",
       "      <td>0.160326</td>\n",
       "      <td>0.497283</td>\n",
       "      <td>-0.154892</td>\n",
       "      <td>23.67</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>0.365994</td>\n",
       "      <td>0.187320</td>\n",
       "      <td>0.446686</td>\n",
       "      <td>-0.080692</td>\n",
       "      <td>26.74</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>0.348601</td>\n",
       "      <td>0.223919</td>\n",
       "      <td>0.427481</td>\n",
       "      <td>-0.078880</td>\n",
       "      <td>28.71</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>0.248634</td>\n",
       "      <td>0.251366</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.251366</td>\n",
       "      <td>45.34</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>0.253731</td>\n",
       "      <td>0.440299</td>\n",
       "      <td>-0.134329</td>\n",
       "      <td>78.55</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>723 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bullish   Neutral   Bearish    Spread   Mean  MaxBear  Median  \\\n",
       "Date                                                                         \n",
       "2006-06-29  0.386000  0.216400  0.397700 -0.011700  56.33   -125.0    65.0   \n",
       "2006-07-06  0.377000  0.196700  0.426200 -0.049200  19.44   -100.0    20.0   \n",
       "2006-07-13  0.365000  0.240900  0.394200 -0.029200  31.20    -50.0    25.0   \n",
       "2006-07-20  0.238500  0.183500  0.578000 -0.339500  18.76   -100.0    25.0   \n",
       "2006-07-27  0.348800  0.220900  0.430200 -0.081400  17.38    -50.0    15.0   \n",
       "...              ...       ...       ...       ...    ...      ...     ...   \n",
       "2020-04-02  0.342391  0.160326  0.497283 -0.154892  23.67   -100.0    20.5   \n",
       "2020-04-09  0.365994  0.187320  0.446686 -0.080692  26.74   -100.0    25.0   \n",
       "2020-04-16  0.348601  0.223919  0.427481 -0.078880  28.71   -100.0    35.0   \n",
       "2020-04-23  0.248634  0.251366  0.500000 -0.251366  45.34   -100.0    50.0   \n",
       "2020-04-30  0.305970  0.253731  0.440299 -0.134329  78.55    -32.0    78.0   \n",
       "\n",
       "            MaxBull  \n",
       "Date                 \n",
       "2006-06-29    125.0  \n",
       "2006-07-06    100.0  \n",
       "2006-07-13    150.0  \n",
       "2006-07-20    100.0  \n",
       "2006-07-27    100.0  \n",
       "...             ...  \n",
       "2020-04-02    100.0  \n",
       "2020-04-09    100.0  \n",
       "2020-04-16    100.0  \n",
       "2020-04-23    200.0  \n",
       "2020-04-30    200.0  \n",
       "\n",
       "[723 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sentiment_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to drop the first 4 entries of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = sentiment_df.iloc[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bullish</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Bearish</th>\n",
       "      <th>Spread</th>\n",
       "      <th>Mean</th>\n",
       "      <th>MaxBear</th>\n",
       "      <th>Median</th>\n",
       "      <th>MaxBull</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2006-06-29</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.216400</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>-0.011700</td>\n",
       "      <td>56.33</td>\n",
       "      <td>-125.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-06</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>0.196700</td>\n",
       "      <td>0.426200</td>\n",
       "      <td>-0.049200</td>\n",
       "      <td>19.44</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-13</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>0.240900</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>-0.029200</td>\n",
       "      <td>31.20</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-20</td>\n",
       "      <td>0.238500</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>-0.339500</td>\n",
       "      <td>18.76</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-27</td>\n",
       "      <td>0.348800</td>\n",
       "      <td>0.220900</td>\n",
       "      <td>0.430200</td>\n",
       "      <td>-0.081400</td>\n",
       "      <td>17.38</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>0.342391</td>\n",
       "      <td>0.160326</td>\n",
       "      <td>0.497283</td>\n",
       "      <td>-0.154892</td>\n",
       "      <td>23.67</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>0.365994</td>\n",
       "      <td>0.187320</td>\n",
       "      <td>0.446686</td>\n",
       "      <td>-0.080692</td>\n",
       "      <td>26.74</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>0.348601</td>\n",
       "      <td>0.223919</td>\n",
       "      <td>0.427481</td>\n",
       "      <td>-0.078880</td>\n",
       "      <td>28.71</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>0.248634</td>\n",
       "      <td>0.251366</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.251366</td>\n",
       "      <td>45.34</td>\n",
       "      <td>-100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>0.253731</td>\n",
       "      <td>0.440299</td>\n",
       "      <td>-0.134329</td>\n",
       "      <td>78.55</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bullish   Neutral   Bearish    Spread   Mean  MaxBear  Median  \\\n",
       "Date                                                                         \n",
       "2006-06-29  0.386000  0.216400  0.397700 -0.011700  56.33   -125.0    65.0   \n",
       "2006-07-06  0.377000  0.196700  0.426200 -0.049200  19.44   -100.0    20.0   \n",
       "2006-07-13  0.365000  0.240900  0.394200 -0.029200  31.20    -50.0    25.0   \n",
       "2006-07-20  0.238500  0.183500  0.578000 -0.339500  18.76   -100.0    25.0   \n",
       "2006-07-27  0.348800  0.220900  0.430200 -0.081400  17.38    -50.0    15.0   \n",
       "...              ...       ...       ...       ...    ...      ...     ...   \n",
       "2020-04-02  0.342391  0.160326  0.497283 -0.154892  23.67   -100.0    20.5   \n",
       "2020-04-09  0.365994  0.187320  0.446686 -0.080692  26.74   -100.0    25.0   \n",
       "2020-04-16  0.348601  0.223919  0.427481 -0.078880  28.71   -100.0    35.0   \n",
       "2020-04-23  0.248634  0.251366  0.500000 -0.251366  45.34   -100.0    50.0   \n",
       "2020-04-30  0.305970  0.253731  0.440299 -0.134329  78.55    -32.0    78.0   \n",
       "\n",
       "            MaxBull  \n",
       "Date                 \n",
       "2006-06-29    125.0  \n",
       "2006-07-06    100.0  \n",
       "2006-07-13    150.0  \n",
       "2006-07-20    100.0  \n",
       "2006-07-27    100.0  \n",
       "...             ...  \n",
       "2020-04-02    100.0  \n",
       "2020-04-09    100.0  \n",
       "2020-04-16    100.0  \n",
       "2020-04-23    200.0  \n",
       "2020-04-30    200.0  \n",
       "\n",
       "[742 rows x 8 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting the sentiment dataframe to a pickle\n",
    "sentiment_df.to_pickle('../Data/sentiment_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment and Stock Data\n",
    "As the sentiment data is released weekly and there tends to be a significant amount of daily variation in stock market data I'm going to take the weekly average closing price. I'm also going to align the date index for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_df = pd.read_pickle('../Data/spy_df')\n",
    "vix_df = pd.read_pickle('../Data/vix_df')\n",
    "qqq_df = pd.read_pickle('../Data/qqq_df')\n",
    "iwm_df = pd.read_pickle('../Data/iwm_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_df=spy_df.resample('W').mean()\n",
    "vix_df=vix_df.resample('W').mean()\n",
    "qqq_df=qqq_df.resample('W').mean()\n",
    "iwm_df=iwm_df.resample('W').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2006-07-02</td>\n",
       "      <td>96.124527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-09</td>\n",
       "      <td>96.086758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-16</td>\n",
       "      <td>94.830073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-23</td>\n",
       "      <td>93.916246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-30</td>\n",
       "      <td>95.820935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>270.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>280.590009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>279.156000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>287.852002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-10</td>\n",
       "      <td>283.570007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close\n",
       "Date                  \n",
       "2006-07-02   96.124527\n",
       "2006-07-09   96.086758\n",
       "2006-07-16   94.830073\n",
       "2006-07-23   93.916246\n",
       "2006-07-30   95.820935\n",
       "...                ...\n",
       "2020-04-12  270.555000\n",
       "2020-04-19  280.590009\n",
       "2020-04-26  279.156000\n",
       "2020-05-03  287.852002\n",
       "2020-05-10  283.570007\n",
       "\n",
       "[724 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2006-07-02</td>\n",
       "      <td>13.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-09</td>\n",
       "      <td>13.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-16</td>\n",
       "      <td>15.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-23</td>\n",
       "      <td>17.108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-30</td>\n",
       "      <td>14.744000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>44.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>39.606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>41.706001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>33.886000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-10</td>\n",
       "      <td>35.970001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Close\n",
       "Date                 \n",
       "2006-07-02  13.080000\n",
       "2006-07-09  13.705000\n",
       "2006-07-16  15.498000\n",
       "2006-07-23  17.108000\n",
       "2006-07-30  14.744000\n",
       "...               ...\n",
       "2020-04-12  44.240000\n",
       "2020-04-19  39.606000\n",
       "2020-04-26  41.706001\n",
       "2020-05-03  33.886000\n",
       "2020-05-10  35.970001\n",
       "\n",
       "[724 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2006-07-02</td>\n",
       "      <td>34.363014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-09</td>\n",
       "      <td>33.891038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-16</td>\n",
       "      <td>32.648847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-23</td>\n",
       "      <td>32.010687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-30</td>\n",
       "      <td>32.453851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>198.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>210.571997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>210.592001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>215.542001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-10</td>\n",
       "      <td>215.220001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close\n",
       "Date                  \n",
       "2006-07-02   34.363014\n",
       "2006-07-09   33.891038\n",
       "2006-07-16   32.648847\n",
       "2006-07-23   32.010687\n",
       "2006-07-30   32.453851\n",
       "...                ...\n",
       "2020-04-12  198.577500\n",
       "2020-04-19  210.571997\n",
       "2020-04-26  210.592001\n",
       "2020-05-03  215.542001\n",
       "2020-05-10  215.220001\n",
       "\n",
       "[724 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qqq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2006-07-02</td>\n",
       "      <td>59.240292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-09</td>\n",
       "      <td>59.099878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-16</td>\n",
       "      <td>57.294521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-23</td>\n",
       "      <td>56.045783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-30</td>\n",
       "      <td>56.942692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>116.834999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>119.990001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>120.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>129.456001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-10</td>\n",
       "      <td>125.680000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close\n",
       "Date                  \n",
       "2006-07-02   59.240292\n",
       "2006-07-09   59.099878\n",
       "2006-07-16   57.294521\n",
       "2006-07-23   56.045783\n",
       "2006-07-30   56.942692\n",
       "...                ...\n",
       "2020-04-12  116.834999\n",
       "2020-04-19  119.990001\n",
       "2020-04-26  120.056000\n",
       "2020-05-03  129.456001\n",
       "2020-05-10  125.680000\n",
       "\n",
       "[724 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iwm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align the stock data index with the sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_df.index = spy_df.index - DateOffset(days=3)\n",
    "vix_df.index = vix_df.index - DateOffset(days=3)\n",
    "qqq_df.index = qqq_df.index - DateOffset(days=3)\n",
    "iwm_df.index = iwm_df.index - DateOffset(days=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add identifier for tickers\n",
    "spy_df['Ticker']= 'SPY'\n",
    "vix_df['Ticker']= 'VIX'\n",
    "qqq_df['Ticker']= 'QQQ'\n",
    "iwm_df['Ticker']= 'IWM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Combined Ticker DF and export all to pickles\n",
    "ticker_df = pd.concat([spy_df,vix_df,qqq_df,iwm_df],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2006-06-29</td>\n",
       "      <td>96.124527</td>\n",
       "      <td>SPY</td>\n",
       "      <td>13.080000</td>\n",
       "      <td>VIX</td>\n",
       "      <td>34.363014</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>59.240292</td>\n",
       "      <td>IWM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-06</td>\n",
       "      <td>96.086758</td>\n",
       "      <td>SPY</td>\n",
       "      <td>13.705000</td>\n",
       "      <td>VIX</td>\n",
       "      <td>33.891038</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>59.099878</td>\n",
       "      <td>IWM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-13</td>\n",
       "      <td>94.830073</td>\n",
       "      <td>SPY</td>\n",
       "      <td>15.498000</td>\n",
       "      <td>VIX</td>\n",
       "      <td>32.648847</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>57.294521</td>\n",
       "      <td>IWM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-20</td>\n",
       "      <td>93.916246</td>\n",
       "      <td>SPY</td>\n",
       "      <td>17.108000</td>\n",
       "      <td>VIX</td>\n",
       "      <td>32.010687</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>56.045783</td>\n",
       "      <td>IWM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-07-27</td>\n",
       "      <td>95.820935</td>\n",
       "      <td>SPY</td>\n",
       "      <td>14.744000</td>\n",
       "      <td>VIX</td>\n",
       "      <td>32.453851</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>56.942692</td>\n",
       "      <td>IWM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>270.555000</td>\n",
       "      <td>SPY</td>\n",
       "      <td>44.240000</td>\n",
       "      <td>VIX</td>\n",
       "      <td>198.577500</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>116.834999</td>\n",
       "      <td>IWM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>280.590009</td>\n",
       "      <td>SPY</td>\n",
       "      <td>39.606000</td>\n",
       "      <td>VIX</td>\n",
       "      <td>210.571997</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>119.990001</td>\n",
       "      <td>IWM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>279.156000</td>\n",
       "      <td>SPY</td>\n",
       "      <td>41.706001</td>\n",
       "      <td>VIX</td>\n",
       "      <td>210.592001</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>120.056000</td>\n",
       "      <td>IWM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>287.852002</td>\n",
       "      <td>SPY</td>\n",
       "      <td>33.886000</td>\n",
       "      <td>VIX</td>\n",
       "      <td>215.542001</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>129.456001</td>\n",
       "      <td>IWM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>283.570007</td>\n",
       "      <td>SPY</td>\n",
       "      <td>35.970001</td>\n",
       "      <td>VIX</td>\n",
       "      <td>215.220001</td>\n",
       "      <td>QQQ</td>\n",
       "      <td>125.680000</td>\n",
       "      <td>IWM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close Ticker  Adj Close Ticker   Adj Close Ticker  \\\n",
       "Date                                                                 \n",
       "2006-06-29   96.124527    SPY  13.080000    VIX   34.363014    QQQ   \n",
       "2006-07-06   96.086758    SPY  13.705000    VIX   33.891038    QQQ   \n",
       "2006-07-13   94.830073    SPY  15.498000    VIX   32.648847    QQQ   \n",
       "2006-07-20   93.916246    SPY  17.108000    VIX   32.010687    QQQ   \n",
       "2006-07-27   95.820935    SPY  14.744000    VIX   32.453851    QQQ   \n",
       "...                ...    ...        ...    ...         ...    ...   \n",
       "2020-04-09  270.555000    SPY  44.240000    VIX  198.577500    QQQ   \n",
       "2020-04-16  280.590009    SPY  39.606000    VIX  210.571997    QQQ   \n",
       "2020-04-23  279.156000    SPY  41.706001    VIX  210.592001    QQQ   \n",
       "2020-04-30  287.852002    SPY  33.886000    VIX  215.542001    QQQ   \n",
       "2020-05-07  283.570007    SPY  35.970001    VIX  215.220001    QQQ   \n",
       "\n",
       "             Adj Close Ticker  \n",
       "Date                           \n",
       "2006-06-29   59.240292    IWM  \n",
       "2006-07-06   59.099878    IWM  \n",
       "2006-07-13   57.294521    IWM  \n",
       "2006-07-20   56.045783    IWM  \n",
       "2006-07-27   56.942692    IWM  \n",
       "...                ...    ...  \n",
       "2020-04-09  116.834999    IWM  \n",
       "2020-04-16  119.990001    IWM  \n",
       "2020-04-23  120.056000    IWM  \n",
       "2020-04-30  129.456001    IWM  \n",
       "2020-05-07  125.680000    IWM  \n",
       "\n",
       "[724 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some dates missing from the stock data, for these ~20 data points I'm going to drop the values from the sentiment dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_df=ticker_df[:-1]\n",
    "spy_df=spy_df[:-1]\n",
    "vix_df=vix_df[:-1]\n",
    "qqq_df=qqq_df[:-1]\n",
    "iwm_df=iwm_df[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.read_pickle('../Data/sentiment_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create lists of the index differences\n",
    "stock_date_list=list(ticker_df.index)\n",
    "sentiment_date_list=list(sentiment_df.index)\n",
    "diff_list = np.setdiff1d(sentiment_date_list,stock_date_list)\n",
    "diff_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the rows from the sentiment dataframe that dont exist in the stock data\n",
    "sentiment_df.drop(diff_list,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that there are no differences left\n",
    "stock_date_list=list(ticker_df.index)\n",
    "sentiment_date_list=list(sentiment_df.index)\n",
    "diff_list = np.setdiff1d(sentiment_date_list,stock_date_list)\n",
    "diff_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(723, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(723, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bullish    0\n",
       "Neutral    0\n",
       "Bearish    0\n",
       "Spread     0\n",
       "Mean       0\n",
       "MaxBear    0\n",
       "Median     0\n",
       "MaxBull    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values\n",
    "sentiment_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bullish    0\n",
       "Neutral    0\n",
       "Bearish    0\n",
       "Spread     0\n",
       "Mean       0\n",
       "MaxBear    0\n",
       "Median     0\n",
       "MaxBull    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are only a small number missing so will simply forward fill\n",
    "sentiment_df.fillna(method='ffill',inplace=True)\n",
    "sentiment_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to pickle\n",
    "ticker_df.to_pickle('../Data/ticker_df')\n",
    "spy_df.to_pickle('../Data/spy_df')\n",
    "vix_df.to_pickle('../Data/vix_df')\n",
    "qqq_df.to_pickle('../Data/qqq_df')\n",
    "iwm_df.to_pickle('../Data/iwm_df')\n",
    "sentiment_df.to_pickle('../Data/sentiment_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New York Times Article Data\n",
    "Here I will remove stop words from my NYT Data as well as tokenize and lemmatize the data before grouping into weekly time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = WordNetLemmatizer()\n",
    "# Create stop words\n",
    "stop_words_ = set(stopwords.words('english'))\n",
    "\n",
    "#Add filter keywords to stop words\n",
    "more_stop_words = ['stock','market','finance','business','price','debt','portfolio','SP500',\n",
    "            'nasdaq','dow jones']\n",
    "\n",
    "stop_words_.update(more_stop_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_txt(token):\n",
    "    '''\n",
    "    This function removes tokens that are in our stop words and punctuation\n",
    "    \n",
    "    Parameters:\n",
    "        Token - words for processing\n",
    "        \n",
    "    Return:\n",
    "        Words without stopwords\n",
    "    '''\n",
    "    return  token not in stop_words_ and token not in list(string.punctuation)  and len(token)>2   \n",
    "  \n",
    "def clean_txt(text):\n",
    "    '''\n",
    "    This function removes unnecessary characters and lemmatizes the strings\n",
    "    \n",
    "    Parameters:\n",
    "        Text - words for processing\n",
    "        \n",
    "    Return:\n",
    "        Clean text\n",
    "    '''\n",
    "    clean_text = []\n",
    "    clean_text2 = []\n",
    "    text = re.sub(\"'\", \"\",text)\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text) \n",
    "    text = text.replace(\"nbsp\", \"\")\n",
    "    clean_text = [ wn.lemmatize(word, pos=\"v\") for word in word_tokenize(text.lower()) if black_txt(word)]\n",
    "    clean_text2 = [word for word in clean_text if black_txt(word)]\n",
    "    return \" \".join(clean_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Snippet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>aventine may late market</td>\n",
       "      <td>share aventine renewable energy hold large eth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>ethanol outfit offer stock</td>\n",
       "      <td>plant nutrient ethanol concern andersons file ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>london stock exchange welcome bollywood player</td>\n",
       "      <td>tuesday next week eros international well know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>house assail media report track finance</td>\n",
       "      <td>largely party line vote lawmakers call news me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>world business brief europe russia convertible...</td>\n",
       "      <td>russian ruble move step closer become fully co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>slum epicenter duterte drug crackdown fear lov...</td>\n",
       "      <td>height president rodrigo duterte anti crime ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>mortgage firm get reprieve pay investors</td>\n",
       "      <td>federal house finance agency say mortgage serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>liu ouqing civil servant help fee wuhan die</td>\n",
       "      <td>china open centrally plan economy liu party se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>richard teitelbaum electronic composer improvi...</td>\n",
       "      <td>teitelbaum whose sonic vocabulary emphasize ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>rupert murdoch son lachlan fox executives take...</td>\n",
       "      <td>company behind fox news fox business fox netwo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34230 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Headline  \\\n",
       "Date                                                            \n",
       "2006-06-30                           aventine may late market   \n",
       "2006-06-30                         ethanol outfit offer stock   \n",
       "2006-06-30     london stock exchange welcome bollywood player   \n",
       "2006-06-30            house assail media report track finance   \n",
       "2006-06-30  world business brief europe russia convertible...   \n",
       "...                                                       ...   \n",
       "2020-04-02  slum epicenter duterte drug crackdown fear lov...   \n",
       "2020-04-21           mortgage firm get reprieve pay investors   \n",
       "2020-04-21        liu ouqing civil servant help fee wuhan die   \n",
       "2020-04-20  richard teitelbaum electronic composer improvi...   \n",
       "2020-04-22  rupert murdoch son lachlan fox executives take...   \n",
       "\n",
       "                                                      Snippet  \n",
       "Date                                                           \n",
       "2006-06-30  share aventine renewable energy hold large eth...  \n",
       "2006-06-30  plant nutrient ethanol concern andersons file ...  \n",
       "2006-06-30  tuesday next week eros international well know...  \n",
       "2006-06-30  largely party line vote lawmakers call news me...  \n",
       "2006-06-30  russian ruble move step closer become fully co...  \n",
       "...                                                       ...  \n",
       "2020-04-02  height president rodrigo duterte anti crime ca...  \n",
       "2020-04-21  federal house finance agency say mortgage serv...  \n",
       "2020-04-21  china open centrally plan economy liu party se...  \n",
       "2020-04-20  teitelbaum whose sonic vocabulary emphasize ot...  \n",
       "2020-04-22  company behind fox news fox business fox netwo...  \n",
       "\n",
       "[34230 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in nyt pickle\n",
    "nyt_df= pd.read_pickle('../Data/nyt_df')\n",
    "nyt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleanning and lemmatizing the headlines and snippets\n",
    "nyt_df['Headline'] = nyt_df['Headline'].apply(clean_txt)\n",
    "nyt_df['Snippet'] = nyt_df['Snippet'].apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Snippet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>aventine may late</td>\n",
       "      <td>share aventine renewable energy hold large eth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>ethanol outfit offer</td>\n",
       "      <td>plant nutrient ethanol concern andersons file ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>london exchange welcome bollywood player</td>\n",
       "      <td>tuesday next week eros international well know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>house assail media report track</td>\n",
       "      <td>largely party line vote lawmakers call news me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>world brief europe russia convertible status n...</td>\n",
       "      <td>russian ruble move step closer become fully co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>slum epicenter duterte drug crackdown fear lov...</td>\n",
       "      <td>height president rodrigo duterte anti crime ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>mortgage firm get reprieve pay investors</td>\n",
       "      <td>federal house agency say mortgage servicers mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>liu ouqing civil servant help fee wuhan die</td>\n",
       "      <td>china open centrally plan economy liu party se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>richard teitelbaum electronic composer improvi...</td>\n",
       "      <td>teitelbaum whose sonic vocabulary emphasize ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>rupert murdoch son lachlan fox executives take...</td>\n",
       "      <td>company behind fox news fox fox network guard ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34230 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Headline  \\\n",
       "Date                                                            \n",
       "2006-06-30                                  aventine may late   \n",
       "2006-06-30                               ethanol outfit offer   \n",
       "2006-06-30           london exchange welcome bollywood player   \n",
       "2006-06-30                    house assail media report track   \n",
       "2006-06-30  world brief europe russia convertible status n...   \n",
       "...                                                       ...   \n",
       "2020-04-02  slum epicenter duterte drug crackdown fear lov...   \n",
       "2020-04-21           mortgage firm get reprieve pay investors   \n",
       "2020-04-21        liu ouqing civil servant help fee wuhan die   \n",
       "2020-04-20  richard teitelbaum electronic composer improvi...   \n",
       "2020-04-22  rupert murdoch son lachlan fox executives take...   \n",
       "\n",
       "                                                      Snippet  \n",
       "Date                                                           \n",
       "2006-06-30  share aventine renewable energy hold large eth...  \n",
       "2006-06-30  plant nutrient ethanol concern andersons file ...  \n",
       "2006-06-30  tuesday next week eros international well know...  \n",
       "2006-06-30  largely party line vote lawmakers call news me...  \n",
       "2006-06-30  russian ruble move step closer become fully co...  \n",
       "...                                                       ...  \n",
       "2020-04-02  height president rodrigo duterte anti crime ca...  \n",
       "2020-04-21  federal house agency say mortgage servicers mu...  \n",
       "2020-04-21  china open centrally plan economy liu party se...  \n",
       "2020-04-20  teitelbaum whose sonic vocabulary emphasize ot...  \n",
       "2020-04-22  company behind fox news fox fox network guard ...  \n",
       "\n",
       "[34230 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there were some additional duplicates now that the text has been cleaned so dropping those\n",
    "nyt_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Snippet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>glass makers fin price fix</td>\n",
       "      <td>european commission issue one largest fin cart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>new captain economy face volatile global market</td>\n",
       "      <td>one reach pinnacle wealth prestige dealmaker w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>google bad business</td>\n",
       "      <td>google wednesday pour cold water speculation m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>nasdaqs greifeld play tortoise talk</td>\n",
       "      <td>nasdaqs chief executive robert greifeld clearl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>glass makers fin price fix</td>\n",
       "      <td>european commission issue one largest fin cart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-06</td>\n",
       "      <td>get</td>\n",
       "      <td>stone clapboard home stockton adobe house sant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-06</td>\n",
       "      <td>home new jersey new mexico wyoming</td>\n",
       "      <td>stone clapboard home stockton adobe house sant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-06</td>\n",
       "      <td>plastic shield homemade lysol grocery persevere</td>\n",
       "      <td>coronavirus upend mundane routine city fresh m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>natural gas export slow pandemic reduce global...</td>\n",
       "      <td>businesses unite state israel countries plan i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>make workplaces safe weird</td>\n",
       "      <td>businesses use safety technologies try protect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34622 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Headline  \\\n",
       "Date                                                            \n",
       "2006-06-01                         glass makers fin price fix   \n",
       "2006-06-01    new captain economy face volatile global market   \n",
       "2006-06-01                                google bad business   \n",
       "2006-06-01                nasdaqs greifeld play tortoise talk   \n",
       "2006-06-01                         glass makers fin price fix   \n",
       "...                                                       ...   \n",
       "2020-05-06                                                get   \n",
       "2020-05-06                 home new jersey new mexico wyoming   \n",
       "2020-05-06    plastic shield homemade lysol grocery persevere   \n",
       "2020-05-11  natural gas export slow pandemic reduce global...   \n",
       "2020-05-12                         make workplaces safe weird   \n",
       "\n",
       "                                                      Snippet  \n",
       "Date                                                           \n",
       "2006-06-01  european commission issue one largest fin cart...  \n",
       "2006-06-01  one reach pinnacle wealth prestige dealmaker w...  \n",
       "2006-06-01  google wednesday pour cold water speculation m...  \n",
       "2006-06-01  nasdaqs chief executive robert greifeld clearl...  \n",
       "2006-06-01  european commission issue one largest fin cart...  \n",
       "...                                                       ...  \n",
       "2020-05-06  stone clapboard home stockton adobe house sant...  \n",
       "2020-05-06  stone clapboard home stockton adobe house sant...  \n",
       "2020-05-06  coronavirus upend mundane routine city fresh m...  \n",
       "2020-05-11  businesses unite state israel countries plan i...  \n",
       "2020-05-12  businesses use safety technologies try protect...  \n",
       "\n",
       "[34622 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step in preprocessing is to remove articles before our start date and after our end date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '06-29-2006'\n",
    "end_date = '04-30-2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nyt_df=nyt_df.loc[(nyt_df.index > start_date) & (nyt_df.index <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Snippet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>aventine may late</td>\n",
       "      <td>share aventine renewable energy hold large eth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>ethanol outfit offer</td>\n",
       "      <td>plant nutrient ethanol concern andersons file ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>london exchange welcome bollywood player</td>\n",
       "      <td>tuesday next week eros international well know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>house assail media report track</td>\n",
       "      <td>largely party line vote lawmakers call news me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>world brief europe russia convertible status n...</td>\n",
       "      <td>russian ruble move step closer become fully co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>slum epicenter duterte drug crackdown fear lov...</td>\n",
       "      <td>height president rodrigo duterte anti crime ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>mortgage firm get reprieve pay investors</td>\n",
       "      <td>federal house agency say mortgage servicers mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>liu ouqing civil servant help fee wuhan die</td>\n",
       "      <td>china open centrally plan economy liu party se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>richard teitelbaum electronic composer improvi...</td>\n",
       "      <td>teitelbaum whose sonic vocabulary emphasize ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>rupert murdoch son lachlan fox executives take...</td>\n",
       "      <td>company behind fox news fox fox network guard ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34230 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Headline  \\\n",
       "Date                                                            \n",
       "2006-06-30                                  aventine may late   \n",
       "2006-06-30                               ethanol outfit offer   \n",
       "2006-06-30           london exchange welcome bollywood player   \n",
       "2006-06-30                    house assail media report track   \n",
       "2006-06-30  world brief europe russia convertible status n...   \n",
       "...                                                       ...   \n",
       "2020-04-02  slum epicenter duterte drug crackdown fear lov...   \n",
       "2020-04-21           mortgage firm get reprieve pay investors   \n",
       "2020-04-21        liu ouqing civil servant help fee wuhan die   \n",
       "2020-04-20  richard teitelbaum electronic composer improvi...   \n",
       "2020-04-22  rupert murdoch son lachlan fox executives take...   \n",
       "\n",
       "                                                      Snippet  \n",
       "Date                                                           \n",
       "2006-06-30  share aventine renewable energy hold large eth...  \n",
       "2006-06-30  plant nutrient ethanol concern andersons file ...  \n",
       "2006-06-30  tuesday next week eros international well know...  \n",
       "2006-06-30  largely party line vote lawmakers call news me...  \n",
       "2006-06-30  russian ruble move step closer become fully co...  \n",
       "...                                                       ...  \n",
       "2020-04-02  height president rodrigo duterte anti crime ca...  \n",
       "2020-04-21  federal house agency say mortgage servicers mu...  \n",
       "2020-04-21  china open centrally plan economy liu party se...  \n",
       "2020-04-20  teitelbaum whose sonic vocabulary emphasize ot...  \n",
       "2020-04-22  company behind fox news fox fox network guard ...  \n",
       "\n",
       "[34230 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_df.to_pickle('../Data/nyt_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the numerical data has been cleaned and the text-based data lemmatized I will move on to some EDA in the next notebook. There will still be a slight amount of processing to do during the sentiment analysis stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
